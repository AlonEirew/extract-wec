# Extract WEC Dataset
This project is following the research paper: (TBD - ADD PAPER LINK).<br/>
Here can be found both The WEC-Eng cross document dataset from English Wikipedia and the method for creating WEC for other languages. <br/>

### WEC-Eng Coreference Dataset
- Datset location is at `WEC/WEC-Eng.zip` folder, split to dev/test/train 
- Dev & Test sets were manually validated, while the train set is unvalidated 

## Generating a new WEC Dataset
Below are the instructions of how-to generate a new version of WEC, whether required from a more recent English Wikipdia dump, 
or in order to extract it from one of the other supported languages (e.g., French, Spanish, German, Chinese). 
### Requisites
* A Wikipedia ElasticSearch Index created by <a href="https://github.com/AlonEirew/wikipedia-to-elastic">wikipedia-to-elastic</a>
  project (index must contain at least the <a href="https://github.com/AlonEirew/wikipedia-to-elastic#project-configuration-files">Infobox</a> "relationTypes").
* Java 11

In order to WEC in current supported languages (e.g., English, French, Spanish, German, Chinese), follow the steps needed in *wikipedia-to-elastic* and below in .

### Processes
This code repo contains two main processes:
1) Code to generate the initial crude version of WEC-Lang
2) Code to generate the final Json of WEC-Lang

### WEC to DB Configuration:
Configuration file - `resources/application.properties`
```
spring.datasource.url=jdbc:h2:file:/demo => h2 database file url
poolSize=8 => Number of thread to run
elasticHost=localhost => Elastic engine host
elasticPort=9200 => (Elastic engine port)
elasticWikiIndex=enwiki_v3 => (Elastic index to read from (as generated by *wikipedia-to-elastic*)
infoboxConfiguration=/infobox_config/en_infobox_config.json => Explained below
multiRequestInterval=100 (recommended value) => Control the number of search pages to retrive from elastic
elasticSearchInterval=100 (recommended value) => Control the number of pages to read by the elasitc scroller
totalAmountToExtract=-1 => if < 0 then read all wikipedia pages, otherwise will read upto the amount specified
```

### WEC to Json Configuration:
```
main.lexicalThresh=4 => lexical diversity threshold
main.outputDir=output => the output folder where WEC json should be created and saved 
main.outputFile=GenWEC.json => WEC json file name, will contain the final version of the generated dataset 
```

### Language Adaptation
We have extracted the relevant infobox configuration for the English Wikipedia. <br/> 
In order to create a newer version of WEC-Eng, use/update the default `infobox_config/en_infobox_config.json` in configuration. <br/>

To generate WEC in one of the supported languages (other than English) follow those steps:
* Export Wikipedia in the required language using *wikipedia-to-elastic* project
* Explore for infoboxs categories, and their correlating names in the required language
* In order to see candidate as well as investigate the amount of pages related to an infobox category. Run:<br/>
`#>java -Xmx90000m -DentityExpansionLimit=2147480000 -DtotalEntitySizeLimit=2147480000 -Djdk.xml.totalEntitySizeLimit=2147480000 -cp "lib/*" scripts.ExtractInfoboxs`<br/>
Report will be generated in `output/InfoboxCount.txt` 
  
#### Infobox configuration file - `resources/infobox_config/*` <br/>
To support a new language, create a new `src/main/resources/infobox_config/<lang>_infobox_config.json` file. 
This file should contain all needed infobox language specific configurations. Finally, set it as the `infoboxConfiguration` file in `application.properties`<br/>

#### English infobox example (from - `en_infobox_config.json`)
```json
{
  "infoboxLangText" : "Infobox",
  "infoboxConfigs": [
    {
      "corefType": "ACCIDENT_EVENT",
      "include": true,
      "infoboxs": [
        "airlinerincident",
        "airlineraccident",
        "aircraftcrash",
        "aircraftaccident",
        "aircraftincident",
        "aircraftoccurrence",
        "railaccident",
        "busaccident",
        "publictransitaccident"
      ]
    }
  ]
}
```

### Project Output
* By default a H2 dataset containing the crude extraction of coreference relations from Wikipedia (this resource can be used for experiments when generating the final version of WEC-Lang)
* A JSON format resource of the WEC-Lang dataset


### Extracting WEC-Lang
Make sure the Wikipedia Elastic engine is running <br/>
* Running WikiToWECMain in order to generate the H2 database:<br/>
  `#>./gradlew bootRun --args=wecdb`
* Generate the WEC-Lang Json format file:<br/> 
  `#>./gradlew bootRun --args=wecjson`
  